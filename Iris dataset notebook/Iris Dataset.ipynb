{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [What is Iris Dataset?](#whatIsIrisDataset)\n",
    "* [Imports](#imports)\n",
    "* [Get the dataset](#getTheDataset)\n",
    "* [Data observation](#dataObservation)\n",
    "* [Data visualization](#dataVisualization)\n",
    "* [Problems with the dataset](#problemsWithTheDataset)\n",
    "* [Using a neural network](#usingNetwork)\n",
    "     - [Linear discriminant analysis](#linearDiscriminantAnalysis)\n",
    "     - [K neighbour classifier](#kNeighbourClassifier)\n",
    "* [Building and training the network](#buildingAndTraining)\n",
    "    - [Imports](#imports2)\n",
    "    - [Linear discriminant](#linearDiscriminant)\n",
    "    - [K neighbours](#kNeighbours)\n",
    "* [References](#references)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a name=\"introduction\"></a>\n",
    "This notebook is concerned with Fisher's Iris data set. In this notebook, I will be explaining the dataset itself, as well as creating easy on the eye visualisations of the dataset. I will also be discussing why it is difficult to write an algorithm that will accurately separate the three species of iris based on the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![](img/iris.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Iris dataset? <a name=\"whatIsIrisDataset\"></a>\n",
    "The Iris dataset was created by British statistician and biologist [Ronald Fisher.](https://en.wikipedia.org/wiki/Ronald_Fisher)\n",
    "in 1936. The dataset itself consists of 150 samples of three species of Iris(setosa,virginica, virsicolor), with 50 samples for each species. Of this dataset, four features were measured from each sample: sepal length, sepal width, petal length, and petal width. This dataset has become a very popular test case in recent years for the techniques used in machine learning. Lets take a look at the actual dataset to get a better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7f867e26bf29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m### so we can read the data from an external url\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[1;31m### so we can style the plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'husl'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### set the default seaborn style to husl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[1;31m### get the plotting package\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd ### so we can read the data from an external url\n",
    "import seaborn as sns ### so we can style the plots\n",
    "sns.set_palette('husl') ### set the default seaborn style to husl\n",
    "import matplotlib.pyplot as plt ### get the plotting package\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset <a name=\"getTheDataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\" ### read in the data from that url\n",
    "headings = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species'] ### give each column a heading \n",
    "data = pd.read_csv(url, names=headings) ### save the data to the data variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data observation <a name=\"dataObservation\"></a>\n",
    "So now that we have read in our data and we have a handle on it, lets have a look at what this dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10) ### view thew top 10 records in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this dataset is comprised of 6 columns. The first column is simply the ID of the samlple. The subsequent columns are named accoringly as sepel-length, sepal-width, petal-length, petal-width and species respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() ### print information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() ### describe what the dataset contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can get a taste for what the dataset contains. We can see statistical information about the dataset, aswell as each numerical column in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['species'].value_counts() ### output the count of each species in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are equal numbers of samples for each species(50 for each)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization <a name=\"dataVisualization\"></a>\n",
    "Now that we have taken a look at what the dataset contains, I think it's time that we actually graph this data so that we can see for ourselves the relationship between each species and the four variables, sepal-length, sepal-width, petal-length, petal-width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.violinplot(y='species', x='sepal-length', data=data, inner='quartile') ### sepal length in cm\n",
    "plt.show()\n",
    "g = sns.violinplot(y='species', x='sepal-width', data=data, inner='quartile') ### sepal width in cm\n",
    "plt.show()\n",
    "g = sns.violinplot(y='species', x='petal-length', data=data, inner='quartile') ### pepal length in cm\n",
    "plt.show()\n",
    "g = sns.violinplot(y='species', x='petal-width', data=data, inner='quartile') ### pepal width in cm\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the the relationship that each species has with each individual variable. We also get a nice illustration of the distribution of each species accross each individual variable.\n",
    "Next, let's take a look at the relationships between all four variables with each of the three species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(data, hue='species', markers='+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, you can clearly see that the Iris-setosa(pink) is distinctly different from those of the other two species. This is because there is almots no overlap between the setosa and the other two species for the four variables in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with the dataset <a name=\"problemsWithTheDataset\"></a>\n",
    "While this may be a fairly extensive dataset, we quickly run into problems when we try to write an algorithm that can accurately predict the species of flower with the four variables we have. This is because of the overlapping that can be seen in the above graph between versicolor and virginica. For example, if you take the (sepal-length,sepal-width) graph, the versicolor and virginica clusters are completely mixed up with eachother making it extremely difficult to construct an algorithm that can percisely differenciate between the two species. The best way to get around this would be to use a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Neural Network <a name=\"usingNetwork\"></a>\n",
    "In this notebook, I will be using two models to build my neural network- \n",
    "*  [LinearDiscriminantAnalysis.](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
    "*  [KNeighborsClassifier.](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "\n",
    "If you want a detailed explanation of what each of those models does, please feel free to click on one of the links which will bring you to their wikipedia page. However I will give a brief summary of what each of them does on a high level here.\n",
    "\n",
    "### Linear Discriminant Analysis <a name=\"linearDiscriminantAnalysis\"></a>\n",
    "Linear discriminant analysis was created by Ronald Fisher in 1936 to characterize or seperate two or more classes of events. This method tries to draw a line of best fit through two of the clusters and estimates that if most of class A lands above the line and most of class B lands below the line, that we can predict the class of an incoming event based on where it lands in relation to the line of best fit.\n",
    "\n",
    " ![](img/linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple picture, we can see that a line of best fit can clearly be drawn between the setosa cluster and the versicolor cluster. Meaning that if another species came in, and its variables placed it above that line we can predict with good percision what it is a setosa. Likewise for the line that can be drawn between versicolor and virginica, however this line would be harder to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbour Classifier <a name=\"kNeighbourClassifier\"></a>\n",
    "The K neighbour classifier is a form of supervised learning in the machine learning world. On a high level, what this algorithm takes its example dataset of, for example three classes, and predicts the class of an incoming event based on the classes that are situated closest to it on a graph.\n",
    "\n",
    "![](img/knn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above image, we can see clearly that if a sample came through with variables placing it near the bottom left corner of the graph, chances are it is a setosa because all of its closest neighbours on the graph are setosa. This may be obvious on the graph displayed above, but if we had three clusters that had overlapping, this algorithm could become very helpful as it would become difficult to perform linear discriminant analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are very high level and oversimplified explanations of the above algorithms just so we can understand better the examples that follow. If you wish to dive deeper into how these algorithms work, please click on the links provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the network <a name=\"buildingAndTraining\"></a>\n",
    "In this section, we are going to construct a neual network with each of the models discussed above, along with training the network from a sample from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports <a name=\"imports2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier ### knn model\n",
    "from sklearn.model_selection import train_test_split ### so we can split the data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis ### linear discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for importing model_selection is so that we can split the data up into two groups, one group for training the network and the other for testing the network. In this case, we will use 75% of the dataset to train the network, and 25% to test the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = data.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n",
    "# random_state is defining a random number seed\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=5) ###for75% train data and 25% test data\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant <a name=\"linearDiscriminant\"></a>\n",
    "\n",
    "First, let us see how accurate we can expect this model to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearDiscriminantAnalysis()\n",
    "linear.fit(X, Y)\n",
    "y_pred = linear.predict(X)\n",
    "print(metrics.accuracy_score(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now input variables to the network and see what species the network believes is it. We will give it fairly low numbers as a test because we know that it should then output setosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.predict([[4,4,1,2]]) ### make a prediction for an example of an out-of-sample observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got back setosa, this is a good sign that the network is working. Now we can start entering more complicated input variables and observing the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K neighbours <a name=\"kNeighbours\"></a>\n",
    "First, let us see how accurate we can expect this model to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=12) ### to measure it up to 12 neighbors\n",
    "knn.fit(X, Y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now input variables to the network and see what species the network believes is it. We will give it fairly low numbers as a test because we know that it should then output setosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn.predict([[4, 4, 1, 2]]) ### make a prediction for an example of an out-of-sample observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got back setosa, this is a good sign that the network is working. Now we can start entering more complicated input variables and observing the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"references\"></a>\n",
    "\n",
    "*  [LinearDiscriminantAnalysis.](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
    "*  [KNeighborsClassifier.](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "* [Machine Learning with Iris Dataset.](https://www.kaggle.com/jchen2186/machine-learning-with-iris-dataset/notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: *Gary Connelly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
